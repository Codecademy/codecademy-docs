---
Title: 'AI Ethics'
Description: 'The study of how AI systems ought to be developed, distributed, and used.'
Subjects:
  - 'AI'
Tags:
  - 'AI'
  - 'Accessibility'
  - 'Deep Learning'
  - 'Neural Networks'
  - 'Justice'
CatalogContent:
  - 'learn-explainable-ai-xai'
  - 'intro-to-ai-strategy'
---

**AI ethics** is the study of ethical issues that arise in the development, distribution, and use of AI systems. As AI-based technologies become more powerful and accurate, they will have a large influence on many aspects of human societies. Already, AI systems are being deployed to help make decisions in finance, law, transportation, employment, and many other areas. It is therefore extremely important for those involved in the development and distribution of AI technologies to carefully consider ethical issues that will arise in the use of these technologies.

Below is a very brief overview of many major ethical issues arising from the growth of AI. The overview is loosely ordered based on immediacy: it begins with issues that already exist and ends with issues are only beginning to arise or may arise in the future. Issues are listed with a definition when necessary, and then a set of central questions arising within that issue. Each of these issues is discussed in greater detail in the term pages below.

## Major Ethical Issues in AI

### Algorithmic Bias

Algorithmic bias occurs when the outputs of an AI algorithm are unfairly biased against a certain group of people.

- How can algorithmic bias be statistically measured and defined?
- What practices should be used to minimize algorithmic bias?

### Ethical Data Collection

- When is it permissible to enter someone's data into an AI system? What type of consent is necessary?
- How can the practical need for large amounts of data in training AI systems be balanced against the requirements for ethical data collection?

### AI and Privacy

- Should there be limits on the development of AI-based identification technologies, such as facial-recognition software?
- How can the potential for misuse of identification technologies be minimized?

### Interpretability and Explainable AI (XAI)

AI systems are often described as "black-boxes" since it is often difficult to explain why an AI system produces a given output. XAI is a field with the goal of developing techniques to explain the processes and outputs of AI systems.

- Do people have a right to an explanation for decisions based on AI systems? In which situations might they have this right?
- How can AI systems be made more transparent and interpretable?

### The Ethics of Robotic AI

Robotic AI is AI software that is embodied in a physical device and given the ability to control that device, such as an autonomous vehicle or autonomous weapon.

- Should there be limits on the development, distribution, or use of certain types of robotic AI?
- Would it be good for robotic AI to replace human-controlled devices? Can both types of devices be allowed to operate in the same spaces?

### AI Automation and Employment

- Will AI replace human forms of work or complement them? If the former, would this be good or bad for human societies?
- What policies should be enacted to distribute wealth produced by gains in productivity due to AI?

### Value Alignment

The challenge of value alignment (also sometimes called *machine ethics*) is to develop AI systems that have ethical values that match human values.

- Which ethical principles and values should govern the decision-making of AI systems?
- How can ethical principles and values be implemented into AI systems?

### AI Rights

- Under what conditions would AI systems have moral rights?
- What would it take for an AI system to be conscious? How can consciousness in AI systems be tested for?

### The Singularity

Some theorists argue that as AI systems become more intelligent, they will eventually be capable of producing even more powerful and intelligent AI systems. This process, they posit, will lead to an exponential growth in the power of AI systems until they far exceed the intelligence and power of anything humanly conceivable. This hypothesized event is known as *The Singularity*.

- Will The Singularity occur, given the present pace of AI development? If so, should AI development be slowed or paused in light of this?
- How can it be ensured that superintelligent AI systems would be aligned with human values?
