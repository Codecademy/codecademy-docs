---
Title: "What is Machine Learning?"
Subjects:
  - "Machine Learning"
  - "Data Science"
  - "Computer Science"
Tags:
  - "AI"
  - "Deep Learning"
  - "Algorithms"
  - "Scikit-learn"
  - "Tensorflow"
  - "Keras"
Catalog Content:
  - "https://www.codecademy.com/learn/machine-learning"
  - "https://www.codecademy.com/learn/paths/data-science"
---
Machine learning (ML) is a discipline of computer science that relates to the use of data and algorithms to development computer programs that improve their performance at tasks without being explicitly programmed to do so. Machine Learning is considered a branch of Artificial Intelligence as some machine learning algorithms are designed to imitate the way that humans learn and interact with their environment.

## Branches of Machine Learning
Machine learning can be categorized into three primary branches:
- Supervised learning: Machine Learning algorithms that receive labeled data as input and produce a prediction as output.
* Regression: Predict a continuous-valued output.
* Classification: Predicts a discrete number of values.

- Unsupervised Learning: Machine Learning algorithms that receive unlabeled data as input and produce a grouping or clustering as output.
* Clustering: Recognize patterns and structures in unlabeled data by grouping them into clusters.
* Dimensionality Reduction: 

- Reinforcement Learning: Machine learning algorithms that receive a state, environment, and goal as input and produce a policy of best action relative to the stated goal as output.
*

### Machine Learning vs. Deep Learning

### Evaluation

As input data is fed into the model, it adjusts its weights until the model has been fitted appropriately. This occurs as part of the cross-validation process to ensure that the model avoids overfitting or underfitting.

Supervised learning helps organizations solve for a variety of real-world problems at scale, such as classifying spam in a separate folder from your inbox.

Some methods used in supervised learning include:

* Linear regression: (straight) line of best fit: The case of one explanatory variable is called simple linear regression; for more than one, the process is called multiple linear regression.

* Logistic regression: a classification algorithm. An interesting nuance is that it provides confidence values with its predictions since the raw output is a probability of a class between 0 and 1. The general process for this is similar to linear regression, where coefficients for various feature weights are altered in order to optimize the accuracy of subsequent predictions from the model.

* Naïve-Bayes classifier: "probabilistic classifiers" based on applying Bayes' theorem with strong (naïve) independence assumptions between the features (see Bayes classifier). They are among the simplest Bayesian network models,[1] but coupled with kernel density estimation, they can achieve higher accuracy levels.

Naive Bayes algorithms extend Bayes' formula to multiple variables by assuming that these features are independent of one another. This then allows you to estimate an overall probability by multiplying the conditional probabilities for each of the independent features.

* Support vector machine (SVM): are supervised learning models with associated learning algorithms that analyze data for classification and regression analysis.

* Neural Networks: Definition here
