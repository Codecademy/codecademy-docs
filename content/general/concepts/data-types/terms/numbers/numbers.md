---
Title: 'Numbers'
Description: 'The numbers data type.'
Subjects:
  - 'Code Foundations'
  - 'Computer Science'
Tags:
  - 'Data Types'
  - 'Types'
CatalogContent:
  - 'paths/code-foundations'
  - 'paths/computer-science'
---


# Numbers

Numbers include `-1`, `0`, `1`, and so on. Depending on the language, numbers with decimals are of a different type. When computing numbers such they trade off acucy for range. Witch means they trade off how acute it is with how many numbers it can compute. Languges such as Javascript and Python do this. This is why when you do this `.1+.2` it would equal `0.30000000000000004`. But if you are adding whole numbers it works all the time. But you need to keep in mind the interger limit. It is the numbere where the compiler wont under stand the numbers any more.
